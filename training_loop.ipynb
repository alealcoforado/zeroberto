{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import nltk\n",
    "import ipywidgets\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import datasets_handler\n",
    "import evaluation_metrics\n",
    "import zeroberto\n",
    "from zeroberto import ZeroBERTo\n",
    "# import datasets\n",
    "# from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/Users/alealcoforado/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7ac5582d6641f89652617307937c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'science and technology', 'sports', 'world']\n"
     ]
    }
   ],
   "source": [
    "# which_dataset = 'folhauol' \n",
    "# which_dataset = 'bbc-news'\n",
    "which_dataset = 'ag_news'\n",
    "\n",
    "hyp_template = \"{}.\"\n",
    "# hyp_template = \"O tema principal deste texto Ã© {}.\"\n",
    "# hyp_template = \"this text is about {}.\"\n",
    "# hyp_template = \"this article is about {}.\"\n",
    "\n",
    "raw_data, data_col, class_col = datasets_handler.getDataset(which_dataset)\n",
    "classes_list = list(raw_data[class_col].unique())\n",
    "print(classes_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroBERTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = 4\n",
    "\n",
    "# max_inferences = len(train) #estava em 5000\n",
    "max_inferences = 500\n",
    "\n",
    "# zeroshot_method = \"probability_threshold\"\n",
    "probability_goal = 0.9\n",
    "top_n_goal = 8\n",
    "\n",
    "use_zeroshot_previous_step = True\n",
    "n = 4\n",
    "top_n = n\n",
    "zeroshot_method = \"dotproduct\"\n",
    "batch_size = 32\n",
    "num_text_pairs = 10\n",
    "num_epochs = 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"zeroshot\" if use_zeroshot_previous_step else \"fewshot\"\n",
    "\n",
    "zeroshot_config = {\n",
    "    'dataset':which_dataset,\n",
    "    'class_col':class_col,\n",
    "    'data_col':data_col,\n",
    "    'split':split,\n",
    "    'method':zeroshot_method,\n",
    "    'prob_goal':probability_goal,\n",
    "    'top_n_goal':top_n_goal,\n",
    "    'max_inferences':max_inferences,\n",
    "    'classes':classes_list,#list(dict_classes_folha.values())\n",
    "    'template': hyp_template,\n",
    "    'random_state':422,\n",
    "    'trainings_done':0,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_pairs\": num_text_pairs,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    'top_n': top_n,\n",
    "    'n_examples': n\n",
    "}\n",
    "\n",
    "\n",
    "train_data = raw_data.sample(zeroshot_config['max_inferences'],random_state=zeroshot_config['random_state']).sort_index()\n",
    "\n",
    "zeroberto_model = ZeroBERTo(classes_list=zeroshot_config['classes'],hypothesis_template=zeroshot_config['template'],\n",
    "                  train_dataset=train_data,labeling_method=zeroshot_config['method'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: 100  - Total time: 5.23 seconds - ETA: 0.4 minutes\n",
      "Preds: 200  - Total time: 9.84 seconds - ETA: 0.4 minutes\n",
      "Preds: 300  - Total time: 14.44 seconds - ETA: 0.4 minutes\n",
      "Preds: 400  - Total time: 19.19 seconds - ETA: 0.4 minutes\n",
      "Preds: 500  - Total time: 23.71 seconds - ETA: 0.4 minutes\n",
      "top 1: {'accuracy': 0.75}\n",
      "top 2: {'accuracy': 0.75}\n",
      "top 3: {'accuracy': 0.8333333333333334}\n",
      "top 4: {'accuracy': 0.8125}\n",
      "top 5: {'accuracy': 0.8}\n",
      "top 6: {'accuracy': 0.75}\n",
      "top 7: {'accuracy': 0.75}\n",
      "top 8: {'accuracy': 0.71875}\n",
      "top 500: {'accuracy': 0.472}\n",
      "ZeroBERTo metrics: {'weighted': [{'accuracy': 0.472}, {'precision': 0.5325776249893898}, {'recall': 0.472}, {'f1': 0.44444732764083916}], 'macro': [{'accuracy': 0.472}, {'precision': 0.5309131228248876}, {'recall': 0.4696565378176432}, {'f1': 0.44160736242716464}]}\n",
      "predictions_and_probabilities_test_2023_02_17__14_49_58.csv\n",
      "zeroshot_config_test_2023_02_17__14_49_58.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Applying column mapping to training dataset\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Body and Head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6093e59fe440e9bb39857bb4cfa082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on 500 sentences.\n",
      "SetFit metrics: {'weighted': [{'accuracy': 0.634}, {'precision': 0.6624396013351639}, {'recall': 0.634}, {'f1': 0.6401919413193805}], 'macro': [{'accuracy': 0.634}, {'precision': 0.6624396013351638}, {'recall': 0.634}, {'f1': 0.6401919413193804}]}\n",
      "metrics_setfit_2023_02_17__14_52_57.csv\n",
      "config_setfit_2023_02_17__14_52_57.csv\n",
      "Preds: 100  - Total time: 4.87 seconds - ETA: 0.4 minutes\n",
      "Preds: 200  - Total time: 9.52 seconds - ETA: 0.4 minutes\n",
      "Preds: 300  - Total time: 14.18 seconds - ETA: 0.4 minutes\n",
      "Preds: 400  - Total time: 18.85 seconds - ETA: 0.4 minutes\n",
      "Preds: 500  - Total time: 23.54 seconds - ETA: 0.4 minutes\n",
      "top 1: {'accuracy': 0.5}\n",
      "top 2: {'accuracy': 0.5}\n",
      "top 3: {'accuracy': 0.3333333333333333}\n",
      "top 4: {'accuracy': 0.25}\n",
      "top 5: {'accuracy': 0.25}\n",
      "top 6: {'accuracy': 0.20833333333333334}\n",
      "top 7: {'accuracy': 0.21428571428571427}\n",
      "top 8: {'accuracy': 0.1875}\n",
      "top 500: {'accuracy': 0.23}\n",
      "ZeroBERTo metrics: {'weighted': [{'accuracy': 0.23}, {'precision': 0.24001495427905173}, {'recall': 0.23}, {'f1': 0.20989516749196174}], 'macro': [{'accuracy': 0.23}, {'precision': 0.24015781362185873}, {'recall': 0.23476652106343138}, {'f1': 0.21220482582934996}]}\n",
      "predictions_and_probabilities_test_2023_02_17__14_53_44.csv\n",
      "zeroshot_config_test_2023_02_17__14_53_44.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Body and Head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93264f5f7e5144c2933438bfa70696ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on 500 sentences.\n",
      "SetFit metrics: {'weighted': [{'accuracy': 0.396}, {'precision': 0.3881211580565028}, {'recall': 0.396}, {'f1': 0.3275591793757188}], 'macro': [{'accuracy': 0.396}, {'precision': 0.3881211580565029}, {'recall': 0.396}, {'f1': 0.3275591793757189}]}\n",
      "metrics_setfit_2023_02_17__14_56_39.csv\n",
      "config_setfit_2023_02_17__14_56_39.csv\n",
      "Preds: 100  - Total time: 4.81 seconds - ETA: 0.4 minutes\n",
      "Preds: 200  - Total time: 9.72 seconds - ETA: 0.4 minutes\n",
      "Preds: 300  - Total time: 14.41 seconds - ETA: 0.4 minutes\n",
      "Preds: 400  - Total time: 18.96 seconds - ETA: 0.4 minutes\n",
      "Preds: 500  - Total time: 23.44 seconds - ETA: 0.4 minutes\n",
      "top 1: {'accuracy': 0.5}\n",
      "top 2: {'accuracy': 0.5}\n",
      "top 3: {'accuracy': 0.5}\n",
      "top 4: {'accuracy': 0.625}\n",
      "top 5: {'accuracy': 0.5}\n",
      "top 6: {'accuracy': 0.4583333333333333}\n",
      "top 7: {'accuracy': 0.42857142857142855}\n",
      "top 8: {'accuracy': 0.40625}\n",
      "top 500: {'accuracy': 0.248}\n",
      "ZeroBERTo metrics: {'weighted': [{'accuracy': 0.248}, {'precision': 0.291060884887946}, {'recall': 0.248}, {'f1': 0.2128052526222434}], 'macro': [{'accuracy': 0.248}, {'precision': 0.2855742878441271}, {'recall': 0.2681290853460665}, {'f1': 0.2217776089758635}]}\n",
      "predictions_and_probabilities_test_2023_02_17__14_57_25.csv\n",
      "zeroshot_config_test_2023_02_17__14_57_25.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training only Head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea3a528a71a4b5981a9c4cba47b5d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on 500 sentences.\n",
      "SetFit metrics: {'weighted': [{'accuracy': 0.486}, {'precision': 0.45985095555096756}, {'recall': 0.486}, {'f1': 0.4375910111071982}], 'macro': [{'accuracy': 0.486}, {'precision': 0.45985095555096756}, {'recall': 0.486}, {'f1': 0.43759101110719817}]}\n",
      "metrics_setfit_2023_02_17__14_57_58.csv\n",
      "config_setfit_2023_02_17__14_57_58.csv\n",
      "Preds: 100  - Total time: 4.68 seconds - ETA: 0.4 minutes\n",
      "Preds: 200  - Total time: 9.17 seconds - ETA: 0.4 minutes\n",
      "Preds: 300  - Total time: 13.67 seconds - ETA: 0.4 minutes\n",
      "Preds: 400  - Total time: 18.2 seconds - ETA: 0.4 minutes\n",
      "Preds: 500  - Total time: 22.61 seconds - ETA: 0.4 minutes\n",
      "top 1: {'accuracy': 0.0}\n",
      "top 2: {'accuracy': 0.0}\n",
      "top 3: {'accuracy': 0.0}\n",
      "top 4: {'accuracy': 0.0625}\n",
      "top 5: {'accuracy': 0.1}\n",
      "top 6: {'accuracy': 0.08333333333333333}\n",
      "top 7: {'accuracy': 0.14285714285714285}\n",
      "top 8: {'accuracy': 0.1875}\n",
      "top 500: {'accuracy': 0.234}\n",
      "ZeroBERTo metrics: {'weighted': [{'accuracy': 0.234}, {'precision': 0.21782555603208248}, {'recall': 0.234}, {'f1': 0.19643750536354493}], 'macro': [{'accuracy': 0.234}, {'precision': 0.21710478128401786}, {'recall': 0.23270805617147078}, {'f1': 0.1950891493196146}]}\n",
      "predictions_and_probabilities_test_2023_02_17__14_58_44.csv\n",
      "zeroshot_config_test_2023_02_17__14_58_44.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training only Head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3315108fbfa94a9eabed87daca2de185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on 500 sentences.\n",
      "SetFit metrics: {'weighted': [{'accuracy': 0.438}, {'precision': 0.4783474950920889}, {'recall': 0.438}, {'f1': 0.3854931891783714}], 'macro': [{'accuracy': 0.438}, {'precision': 0.4783474950920889}, {'recall': 0.43799999999999994}, {'f1': 0.38549318917837133}]}\n",
      "metrics_setfit_2023_02_17__14_59_23.csv\n",
      "config_setfit_2023_02_17__14_59_23.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for training_step in range(num_training_steps):\n",
    "\n",
    "    results = zeroberto.runZeroberto(zeroberto_model,train_data['text'],zeroshot_config)  \n",
    "\n",
    "    df_results = zeroberto_model.evaluateLabeling(results,top_n=8)\n",
    "\n",
    "    all_metrics = evaluation_metrics.get_metrics(df_results['prediction_code'].to_list(),df_results['class_code'].to_list())\n",
    "    print(\"ZeroBERTo metrics:\",all_metrics)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    save_time = evaluation_metrics.saveZeroshotResults(zeroshot_config,df_results)\n",
    "\n",
    "    zeroshot_config['exec_time'] = save_time\n",
    "\n",
    "    zeroshot_previous_data = datasets_handler.getZeroshotPreviousData(which_dataset,class_col,top_n=top_n,exec_time=zeroshot_config['exec_time'] )\n",
    "    raw_data_final, zeroshot_config['new_class_col'] = datasets_handler.mergeLabelingToDataset(raw_data,zeroshot_previous_data,class_col)\n",
    "\n",
    "    df_train, df_test = datasets_handler.splitDataset(raw_data_final,zeroshot_config)\n",
    "    train_dataset,test_dataset = datasets_handler.buildDatasetDict(df_train,df_test)\n",
    "\n",
    "    if (zeroshot_config['trainings_done'] <= 0):\n",
    "\n",
    "        zeroshot_config['setfit_model'] = 'sentence-transformers/stsb-xlm-r-multilingual'\n",
    "        setfit_model = SetFitModel.from_pretrained(zeroshot_config['setfit_model'],\n",
    "                                            use_differentiable_head=True,\n",
    "                                            head_params={\"out_features\":len(zeroshot_config['classes'])})\n",
    "    else:\n",
    "        setfit_model.model_body = new_embeddingModel\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = SetFitTrainer(\n",
    "        model=setfit_model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        loss_class=CosineSimilarityLoss,\n",
    "        batch_size=zeroshot_config[\"batch_size\"],\n",
    "        num_iterations=zeroshot_config[\"num_pairs\"], # Number of text pairs to generate for contrastive learning\n",
    "        num_epochs=zeroshot_config[\"num_epochs\"], # Number of epochs to use for contrastive learning\n",
    "        column_mapping = {data_col: \"text\", 'class_code': \"label\"} # NÃO mudar\n",
    "    )\n",
    "\n",
    "    #### Train and evaluate SetFit Model\n",
    "\n",
    "    # trainer.freeze() # Freeze the head\n",
    "    # trainer.train() # Train only the body\n",
    "  \n",
    "    if (zeroshot_config['trainings_done'] <= 1):\n",
    "        #### Unfreeze the head and unfreeze the body -> end-to-end training\n",
    "        trainer.unfreeze(keep_body_frozen=False)\n",
    "        print(\"Training Body and Head.\")\n",
    "    else:\n",
    "        #### Unfreeze the head and freeze the body -> head-only training\n",
    "        trainer.unfreeze(keep_body_frozen=True)\n",
    "        zeroshot_config[\"num_epochs\"] = 2\n",
    "        print(\"Training only Head.\")\n",
    "\n",
    "    trainer.train(\n",
    "        num_epochs=zeroshot_config[\"num_epochs\"], # The number of epochs to train the head or the whole model (body and head)\n",
    "        batch_size=zeroshot_config[\"batch_size\"],\n",
    "        body_learning_rate=1e-5, # The body's learning rate\n",
    "        learning_rate=1e-2, # The head's learning rate\n",
    "        l2_weight=0.01, # Weight decay on **both** the body and head. If `None`, will use 0.01.\n",
    "    )\n",
    "\n",
    "    zeroshot_config['trainings_done'] += 1\n",
    "    gc.collect()\n",
    "\n",
    "    y_pred = zeroberto.getPredictions(trainer)\n",
    "\n",
    "    all_metrics = evaluation_metrics.get_metrics(y_pred ,test_dataset[\"class_code\"])\n",
    "    print(\"SetFit metrics:\",all_metrics)\n",
    "\n",
    "    new_embeddingModel = trainer.model.model_body\n",
    "\n",
    "    zeroberto_model.embeddingModel = new_embeddingModel\n",
    "    evaluation_metrics.saveResults(zeroshot_config,all_metrics)\n",
    "\n",
    "    zeroshot_config['random_state'] += 1\n",
    "    zeroberto_model.train_dataset = raw_data.sample(zeroshot_config['max_inferences'],random_state=zeroshot_config['random_state']).sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_zeroberto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b98a7e24f8a69e8a460c693288d2fe0565d17bd4bdd6eb6203258b225132cc92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
