prox passos
1) testar modelo como está nos datasets benchmark (começar por AgNews)
2) pesquisa + resumir papers do EMNLP de 0shot (e outros)
3) definir experimentos
4) testar similarity do sBERT (ver tempo de execução e se melhora acurácia)


n) organizar código pra mandar o paper
n+1) organizar pra submeter no hugging face
m) 

---estrutura paper---

1) intro

2) Related Work
revisao do estado da arte 
ja vamos usar umas ideias dos outros

3) descrição do método
a) seleção (sentence extraction + clusterizaçao?? + heurística??)
b) rotulagem
c) treinamento

4) experimentos e resultados do modelo
principal resultado do modelo

5) e 6) tentar avaliar o papel de cada hiperparametro de cada fase 
cada vez q roda o self training, oq acontece?...
estudo de ablação + gráficos
heatmaps


---------------

resultados de papers:
F1: 81.4 --- Ag News

https://aclanthology.org/2022.emnlp-main.509.pdf
AG NEWS - acc 79.2 
YAHOO - acc 56.1
DBPEDIA - acc 80.4
AMAZON - acc 92.0
IMDB - acc 86.7


##### paper foda #####
https://aclanthology.org/2022.emnlp-main.587.pdf
AG NEWS - acc 86.9
YAHOO - acc 63.9
DBPEDIA - acc 93.2
AMAZON - acc 93.9
IMDB - acc 91.0


drive paths

# data_path = '/content/drive/Othercomputers/My MacBook Pro/Datasets/folhauol/folhauol_clean_df_articles.csv'
data_path = '/content/drive/MyDrive/Maquina de London/clean_df_articles_folhauol.csv'
