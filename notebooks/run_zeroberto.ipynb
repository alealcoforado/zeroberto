{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcRIbaP7p2VG",
        "outputId": "4a9e56d5-2607-47f2-f0eb-8d28f2ed114f"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/alealcoforado/ZeroBERTo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK8rnsJHqDmx",
        "outputId": "cd180ed1-c839-4d66-c2ff-a1f9f29bad0c"
      },
      "outputs": [],
      "source": [
        "# !pip install -r /Users/alealcoforado/Documents/Projetos/zeroberto/requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Found cached dataset json (/Users/alealcoforado/.cache/huggingface/datasets/SetFit___json/SetFit--CR-55cf29835d8d8adf/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 415.61it/s]\n",
            "Loading cached shuffled indices for dataset at /Users/alealcoforado/.cache/huggingface/datasets/SetFit___json/SetFit--CR-55cf29835d8d8adf/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-0ca2d2b2c06fabe0.arrow\n",
            "Start training\n",
            "Running First-Shot on 1000 documents.\n",
            "['This text is negative.', 'This text is positive.'] [0 1]\n",
            "** Training body **\n",
            "Num examples = 40\n",
            "Num body epochs = 5\n",
            "Total optimization steps = 25\n",
            "Total train batch size = 8\n",
            "** Training head **\n",
            "Num epochs = 1\n",
            "1st shot - train and prediction time: 23.78 seconds\n",
            "full_train_trained_first_shot: ----- accuracy: 0.707\n",
            "eval_trained_first_shot ----- accuracy: 0.7313829787234043\n",
            "1st shot - cosine product time: 46.1 seconds\n",
            "full_train_raw_first_shot ----- accuracy: 0.688\n",
            "Data Selector roadmap: [4, 8]\n",
            "********** Running SetFit Iteration 1 **********\n",
            "Data Selected: 8\n",
            "data_selector-1 ----- accuracy: 0.875\n",
            "** Training body **\n",
            "Num examples = 160\n",
            "Num body epochs = 1\n",
            "Total optimization steps = 20\n",
            "Total train batch size = 8\n",
            "** Training head **\n",
            "Num epochs = 1\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/alealcoforado/Documents/Projetos/zeroberto/train_eval.py\", line 225, in <module>\n",
            "    main()\n",
            "  File \"/Users/alealcoforado/Documents/Projetos/zeroberto/train_eval.py\", line 215, in main\n",
            "    train_history = trainer.train(return_history=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/Documents/Projetos/zeroberto/ZeroBERTo/trainer.py\", line 339, in train\n",
            "    probs, embeds = self.model.predict_proba(train_dataset[\"text\"], return_embeddings=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/Documents/Projetos/zeroberto/ZeroBERTo/modeling_zeroberto.py\", line 417, in predict_proba\n",
            "    embeddings = self.model_body.encode(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py\", line 165, in encode\n",
            "    out_features = self.forward(features)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py\", line 66, in forward\n",
            "    output_states = self.auto_model(**trans_features, return_dict=False)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 1020, in forward\n",
            "    encoder_outputs = self.encoder(\n",
            "                      ^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 610, in forward\n",
            "    layer_outputs = layer_module(\n",
            "                    ^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 537, in forward\n",
            "    layer_output = apply_chunking_to_forward(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/transformers/pytorch_utils.py\", line 236, in apply_chunking_to_forward\n",
            "    return forward_fn(*input_tensors)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 549, in feed_forward_chunk\n",
            "    intermediate_output = self.intermediate(attention_output)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 449, in forward\n",
            "    hidden_states = self.dense(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/alealcoforado/opt/anaconda3/envs/venv_zeroberto/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python train_eval.py --hypothesis_template=\"This text is {}.\" --dataset='SetFit/CR' --num_iterations=10 --num_setfit_iterations=2 --num_epochs=1 --var_samples_per_label 4 8 --first_shot_train --model_name_or_path='sentence-transformers/all-MiniLM-L6-v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "!python train_eval.py --hypothesis_template=\"This text is {}.\" --dataset='SetFit/ag_news' --num_iterations=10 --num_setfit_iterations=2 --num_epochs=1 --var_samples_per_label 4 8 --first_shot_train --model_name_or_path='sentence-transformers/all-MiniLM-L6-v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
