{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alealcoforado/Documents/Projetos/ZeroBERTo/zeroberto corrigido/zeroberto/datasets_handler.py:159: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import nltk\n",
    "import ipywidgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import datasets_handler\n",
    "import evaluation_metrics\n",
    "import zeroberto\n",
    "from zeroberto import ZeroBERTo\n",
    "# import datasets\n",
    "# from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/alealcoforado/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495e065e6aea4ec498dcb89c6fd58525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label']\n"
     ]
    }
   ],
   "source": [
    "# which_dataset = 'folhauol' \n",
    "# which_dataset = 'bbc-news'\n",
    "which_dataset = 'ag_news'\n",
    "which_dataset = 'imdb'\n",
    "\n",
    "\n",
    "hyp_template = \"{}\"\n",
    "# hyp_template = \"O tema principal deste texto Ã© {}.\"\n",
    "# hyp_template = \"this text is about {}.\"\n",
    "# hyp_template = \"this article is about {}.\"\n",
    "\n",
    "raw_data, data_col, class_col = datasets_handler.getDataset(which_dataset)\n",
    "classes_list = list(raw_data[class_col].unique())\n",
    "print(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroBERTo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'imdb',\n",
       " 'class_col': 'class',\n",
       " 'data_col': 'text',\n",
       " 'split': 'zeroshot',\n",
       " 'method': 'dotproduct',\n",
       " 'prob_goal': 0.9,\n",
       " 'top_n_goal': 8,\n",
       " 'max_inferences': 5000,\n",
       " 'classes': ['text', 'label'],\n",
       " 'template': '{}',\n",
       " 'random_state': 422,\n",
       " 'trainings_done': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_inferences = len(train) #estava em 5000\n",
    "max_inferences = 5000\n",
    "\n",
    "# zeroshot_method = \"probability_threshold\"\n",
    "probability_goal = 0.9\n",
    "top_n_goal = 8\n",
    "\n",
    "zeroshot_method = \"dotproduct\"  \n",
    "# zeroshot_method = \"kmeans\"  \n",
    "\n",
    "zeroshot_config = {\n",
    "    'dataset':which_dataset,\n",
    "    'class_col':class_col,\n",
    "    'data_col':data_col,\n",
    "    'split':\"zeroshot\",\n",
    "    'method':zeroshot_method,\n",
    "    'prob_goal':probability_goal,\n",
    "    'top_n_goal':top_n_goal,\n",
    "    'max_inferences':max_inferences,\n",
    "    'classes':classes_list,#list(dict_classes_folha.values())\n",
    "    'template': hyp_template,\n",
    "    'random_state':422,\n",
    "    'trainings_done':0\n",
    "}\n",
    "zeroshot_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = raw_data.sample(zeroshot_config['max_inferences'],random_state=zeroshot_config['random_state']).sort_index()\n",
    "len(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZeroBERTo(classes_list=zeroshot_config['classes'],hypothesis_template=zeroshot_config['template'],\n",
    "                  train_dataset=train_data,labeling_method=zeroshot_config['method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.embeddingModel = new_embeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: 100  - Total time: 7.37 seconds - ETA: 6.1 minutes\n",
      "Preds: 200  - Total time: 14.29 seconds - ETA: 6.0 minutes\n",
      "Preds: 300  - Total time: 21.44 seconds - ETA: 6.0 minutes\n",
      "Preds: 400  - Total time: 29.21 seconds - ETA: 6.1 minutes\n",
      "Preds: 500  - Total time: 36.97 seconds - ETA: 6.2 minutes\n",
      "Preds: 600  - Total time: 44.15 seconds - ETA: 6.1 minutes\n",
      "Preds: 700  - Total time: 51.02 seconds - ETA: 6.1 minutes\n",
      "Preds: 800  - Total time: 58.01 seconds - ETA: 6.0 minutes\n",
      "Preds: 900  - Total time: 64.96 seconds - ETA: 6.0 minutes\n",
      "Preds: 1000  - Total time: 72.57 seconds - ETA: 6.0 minutes\n",
      "Preds: 1100  - Total time: 79.92 seconds - ETA: 6.1 minutes\n",
      "Preds: 1200  - Total time: 87.22 seconds - ETA: 6.1 minutes\n",
      "Preds: 1300  - Total time: 94.92 seconds - ETA: 6.1 minutes\n",
      "Preds: 1400  - Total time: 102.34 seconds - ETA: 6.1 minutes\n",
      "Preds: 1500  - Total time: 109.5 seconds - ETA: 6.1 minutes\n",
      "Preds: 1600  - Total time: 116.19 seconds - ETA: 6.1 minutes\n",
      "Preds: 1700  - Total time: 123.33 seconds - ETA: 6.0 minutes\n",
      "Preds: 1800  - Total time: 131.48 seconds - ETA: 6.1 minutes\n",
      "Preds: 1900  - Total time: 138.82 seconds - ETA: 6.1 minutes\n",
      "Preds: 2000  - Total time: 145.59 seconds - ETA: 6.1 minutes\n",
      "Preds: 2100  - Total time: 152.34 seconds - ETA: 6.0 minutes\n",
      "Preds: 2200  - Total time: 159.11 seconds - ETA: 6.0 minutes\n",
      "Preds: 2300  - Total time: 165.9 seconds - ETA: 6.0 minutes\n",
      "Preds: 2400  - Total time: 172.7 seconds - ETA: 6.0 minutes\n",
      "Preds: 2500  - Total time: 180.03 seconds - ETA: 6.0 minutes\n",
      "Preds: 2600  - Total time: 187.79 seconds - ETA: 6.0 minutes\n",
      "Preds: 2700  - Total time: 196.26 seconds - ETA: 6.1 minutes\n",
      "Preds: 2800  - Total time: 203.06 seconds - ETA: 6.0 minutes\n",
      "Preds: 2900  - Total time: 209.81 seconds - ETA: 6.0 minutes\n",
      "Preds: 3000  - Total time: 216.88 seconds - ETA: 6.0 minutes\n",
      "Preds: 3100  - Total time: 223.77 seconds - ETA: 6.0 minutes\n",
      "Preds: 3200  - Total time: 230.49 seconds - ETA: 6.0 minutes\n",
      "Preds: 3300  - Total time: 237.26 seconds - ETA: 6.0 minutes\n",
      "Preds: 3400  - Total time: 244.0 seconds - ETA: 6.0 minutes\n",
      "Preds: 3500  - Total time: 250.66 seconds - ETA: 6.0 minutes\n",
      "Preds: 3600  - Total time: 257.48 seconds - ETA: 6.0 minutes\n",
      "Preds: 3700  - Total time: 264.21 seconds - ETA: 6.0 minutes\n",
      "Preds: 3800  - Total time: 270.96 seconds - ETA: 5.9 minutes\n",
      "Preds: 3900  - Total time: 277.66 seconds - ETA: 5.9 minutes\n",
      "Preds: 4000  - Total time: 284.31 seconds - ETA: 5.9 minutes\n",
      "Preds: 4100  - Total time: 291.1 seconds - ETA: 5.9 minutes\n",
      "Preds: 4200  - Total time: 297.75 seconds - ETA: 5.9 minutes\n",
      "Preds: 4300  - Total time: 305.09 seconds - ETA: 5.9 minutes\n",
      "Preds: 4400  - Total time: 312.58 seconds - ETA: 5.9 minutes\n",
      "Preds: 4500  - Total time: 319.58 seconds - ETA: 5.9 minutes\n",
      "Preds: 4600  - Total time: 326.27 seconds - ETA: 5.9 minutes\n",
      "Preds: 4700  - Total time: 333.05 seconds - ETA: 5.9 minutes\n",
      "Preds: 4800  - Total time: 339.99 seconds - ETA: 5.9 minutes\n",
      "Preds: 4900  - Total time: 347.17 seconds - ETA: 5.9 minutes\n",
      "Preds: 5000  - Total time: 354.93 seconds - ETA: 5.9 minutes\n"
     ]
    }
   ],
   "source": [
    "results = zeroberto.runZeroberto(model,train_data[data_col].to_list(),zeroshot_config)  ##X## COMENTAR AQUI "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1: {'accuracy': 1.0}\n",
      "top 2: {'accuracy': 1.0}\n",
      "top 3: {'accuracy': 1.0}\n",
      "top 4: {'accuracy': 0.875}\n",
      "top 5: {'accuracy': 0.8}\n",
      "top 6: {'accuracy': 0.8333333333333334}\n",
      "top 7: {'accuracy': 0.8571428571428571}\n",
      "top 8: {'accuracy': 0.875}\n",
      "top 9: {'accuracy': 0.8333333333333334}\n",
      "top 10: {'accuracy': 0.8}\n",
      "top 11: {'accuracy': 0.7727272727272727}\n",
      "top 12: {'accuracy': 0.75}\n",
      "top 13: {'accuracy': 0.7692307692307693}\n",
      "top 14: {'accuracy': 0.7857142857142857}\n",
      "top 15: {'accuracy': 0.8}\n",
      "top 16: {'accuracy': 0.75}\n",
      "top 5000: {'accuracy': 0.5662}\n"
     ]
    }
   ],
   "source": [
    "df_results = model.evaluateLabeling(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weighted': [{'accuracy': 0.567}, {'precision': 0.5675149000253721}, {'recall': 0.567}, {'f1': 0.5666831361790388}], 'macro': [{'accuracy': 0.567}, {'precision': 0.5674436559967043}, {'recall': 0.5672463275556059}, {'f1': 0.5667708217647136}]}\n",
      "{'weighted': [{'accuracy': 0.5662}, {'precision': 0.5788214975324903}, {'recall': 0.5662}, {'f1': 0.5448947200842807}], 'macro': [{'accuracy': 0.5662}, {'precision': 0.5790837005029481}, {'recall': 0.5643024195793722}, {'f1': 0.5440095148753178}]}\n"
     ]
    }
   ],
   "source": [
    "try: print(zeroshot_metrics)\n",
    "except: pass\n",
    "zeroshot_metrics = evaluation_metrics.get_metrics(df_results['prediction_code'].to_list(),df_results['class_code'].to_list())\n",
    "print(zeroshot_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_and_probabilities_test_2023_03_09__23_25_37.csv\n",
      "zeroshot_config_test_2023_03_09__23_25_37.csv\n"
     ]
    }
   ],
   "source": [
    "save_time = evaluation_metrics.saveZeroshotResults(zeroshot_config,df_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_zeroshot_previous_step = True\n",
    "n = 8\n",
    "top_n = 8\n",
    "zeroshot_config['top_n'] = top_n\n",
    "zeroshot_config['n_examples'] = n\n",
    "zeroshot_config['exec_time'] = save_time\n",
    "\n",
    "zeroshot_config['st_train_epochs'] = 10\n",
    "zeroshot_config['st_train_batch_size'] = 20\n",
    "\n",
    "\n",
    "split = \"zeroshot\" if use_zeroshot_previous_step else \"fewshot\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_previous_data = datasets_handler.getZeroshotPreviousData(which_dataset,class_col,top_n=top_n,exec_time=zeroshot_config['exec_time'])\n",
    "raw_data_final, zeroshot_config['new_class_col'] = datasets_handler.mergeLabelingToDataset(raw_data,zeroshot_previous_data,class_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = datasets_handler.splitDataset(raw_data_final,zeroshot_config)\n",
    "train_dataset,test_dataset = datasets_handler.buildDatasetDict(df_train,df_test)\n",
    "train_documents = datasets_handler.splitDocuments(df_train[data_col])\n",
    "len(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Corpo do Modelo -- nÃ£o descomentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_documents,batch_size=zeroshot_config['st_train_batch_size'],epochs=zeroshot_config['st_train_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning (SetFit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "zeroshot_config['setfit_model'] = 'sentence-transformers/stsb-xlm-r-multilingual'\n",
    "\n",
    "setfit_model = SetFitModel.from_pretrained(zeroshot_config['setfit_model'],\n",
    "                                    use_differentiable_head=True,\n",
    "                                    head_params={\"out_features\":len(zeroshot_config['classes'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "setfit_model.model_body = model.embeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'imdb',\n",
       " 'class_col': 'class',\n",
       " 'data_col': 'text',\n",
       " 'split': 'zeroshot',\n",
       " 'method': 'dotproduct',\n",
       " 'prob_goal': 0.9,\n",
       " 'top_n_goal': 8,\n",
       " 'max_inferences': 5000,\n",
       " 'classes': ['text', 'label'],\n",
       " 'template': '{}',\n",
       " 'random_state': 422,\n",
       " 'trainings_done': 1,\n",
       " 'top_n': 8,\n",
       " 'n_examples': 8,\n",
       " 'exec_time': '2023_03_09__23_25_37',\n",
       " 'st_train_epochs': 10,\n",
       " 'st_train_batch_size': 20,\n",
       " 'new_class_col': 'new_class',\n",
       " 'setfit_model': 'sentence-transformers/stsb-xlm-r-multilingual',\n",
       " 'batch_size': 8,\n",
       " 'num_pairs': 15,\n",
       " 'num_epochs': 30}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "num_text_pairs = 15\n",
    "num_epochs = 30\n",
    "\n",
    "zeroshot_config[\"batch_size\"] = batch_size\n",
    "zeroshot_config[\"num_pairs\"] = num_text_pairs\n",
    "zeroshot_config[\"num_epochs\"] = num_epochs\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=setfit_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=zeroshot_config[\"batch_size\"],\n",
    "    num_iterations=zeroshot_config[\"num_pairs\"], # Number of text pairs to generate for contrastive learning\n",
    "    num_epochs=zeroshot_config[\"num_epochs\"], # Number of epochs to use for contrastive learning\n",
    "    column_mapping = {data_col: \"text\", 'class_code': \"label\"} # NÃO mudar\n",
    ")\n",
    "zeroshot_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 128.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9072dbf0f48a43cf91c1131ca4a7b824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'imdb', 'class_col': 'class', 'data_col': 'text', 'split': 'zeroshot', 'method': 'dotproduct', 'prob_goal': 0.9, 'top_n_goal': 8, 'max_inferences': 5000, 'classes': ['text', 'label'], 'template': '{}', 'random_state': 422, 'trainings_done': 3, 'top_n': 8, 'n_examples': 8, 'exec_time': '2023_03_09__23_25_37', 'st_train_epochs': 10, 'st_train_batch_size': 20, 'new_class_col': 'new_class', 'setfit_model': 'sentence-transformers/stsb-xlm-r-multilingual', 'batch_size': 8, 'num_pairs': 15, 'num_epochs': 30}\n",
      "CPU times: user 2min 15s, sys: 6min 12s, total: 8min 28s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train and evaluate\n",
    "# trainer.freeze() # Freeze the head\n",
    "# trainer.train() # Train only the body\n",
    "\n",
    "# Unfreeze the head and freeze the body -> head-only training\n",
    "trainer.unfreeze(keep_body_frozen=True)\n",
    "\n",
    "# Unfreeze the head and unfreeze the body -> end-to-end training\n",
    "# trainer.unfreeze(keep_body_frozen=False)\n",
    "\n",
    "trainer.train(\n",
    "    num_epochs=zeroshot_config[\"num_epochs\"], # The number of epochs to train the head or the whole model (body and head)\n",
    "    batch_size=zeroshot_config[\"batch_size\"],\n",
    "    body_learning_rate=1e-5, # The body's learning rate\n",
    "    learning_rate=1e-2, # The head's learning rate\n",
    "    l2_weight=0.1, # Weight decay on **both** the body and head. If `None`, will use 0.01.\n",
    ")\n",
    "\n",
    "zeroshot_config['trainings_done'] += 1\n",
    "\n",
    "print(zeroshot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on 5000 sentences.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "y_pred = zeroberto.getPredictions(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weighted': [{'accuracy': 0.6246}, {'precision': 0.6480520344678443}, {'recall': 0.6246}, {'f1': 0.6091207925039489}], 'macro': [{'accuracy': 0.6246}, {'precision': 0.6480520344678444}, {'recall': 0.6246}, {'f1': 0.6091207925039489}]}\n",
      "{'weighted': [{'accuracy': 0.5736}, {'precision': 0.693523199224561}, {'recall': 0.5736}, {'f1': 0.4954318119166699}], 'macro': [{'accuracy': 0.5736}, {'precision': 0.693523199224561}, {'recall': 0.5736}, {'f1': 0.49543181191666996}]}\n"
     ]
    }
   ],
   "source": [
    "try: print(setfit_all_metrics)\n",
    "except: pass\n",
    "setfit_all_metrics = evaluation_metrics.get_metrics(y_pred ,test_dataset[\"class_code\"])\n",
    "print(setfit_all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_embeddingModel = trainer.model.model_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_setfit_2023_03_09__14_05_21.csv\n",
      "config_setfit_2023_03_09__14_05_21.csv\n",
      "{'dataset': 'ag_news', 'class_col': 'class', 'data_col': 'text', 'split': 'zeroshot', 'method': 'dotproduct', 'prob_goal': 0.9, 'top_n_goal': 8, 'max_inferences': 5000, 'classes': ['business', 'science and technology', 'sports', 'world'], 'template': '{}', 'random_state': 422, 'trainings_done': 1, 'top_n': 8, 'n_examples': 8, 'exec_time': '2023_03_09__13_53_41', 'st_train_epochs': 10, 'st_train_batch_size': 20, 'new_class_col': 'new_class', 'setfit_model': 'sentence-transformers/stsb-xlm-r-multilingual', 'batch_size': 8, 'num_pairs': 15, 'num_epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "setfit_exec_time  = evaluation_metrics.saveResults(zeroshot_config,setfit_all_metrics)\n",
    "print(zeroshot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alealcoforado/Documents/Projetos/Modelos/2023_03_09__14_05_21\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/Users/alealcoforado/Documents/Projetos/Modelos/{exec}\".format(exec=setfit_exec_time)\n",
    "print(model_path)\n",
    "trainer.model._save_pretrained(save_directory=model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroBERTo 2nd run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZeroBERTo(classes_list=zeroshot_config['classes'],hypothesis_template=zeroshot_config['template'],\n",
    "                  train_dataset=train_data,labeling_method=zeroshot_config['method'],embeddingModel=new_embeddingModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: 100  - Total time: 9.34 seconds - ETA: 3.1 minutes\n",
      "Preds: 200  - Total time: 18.15 seconds - ETA: 3.0 minutes\n",
      "Preds: 300  - Total time: 27.15 seconds - ETA: 3.0 minutes\n",
      "Preds: 400  - Total time: 35.55 seconds - ETA: 3.0 minutes\n",
      "Preds: 500  - Total time: 43.84 seconds - ETA: 2.9 minutes\n",
      "Preds: 600  - Total time: 52.08 seconds - ETA: 2.9 minutes\n",
      "Preds: 700  - Total time: 60.36 seconds - ETA: 2.9 minutes\n",
      "Preds: 800  - Total time: 66.73 seconds - ETA: 2.8 minutes\n",
      "Preds: 900  - Total time: 72.23 seconds - ETA: 2.7 minutes\n",
      "Preds: 1000  - Total time: 77.5 seconds - ETA: 2.6 minutes\n",
      "Preds: 1100  - Total time: 82.88 seconds - ETA: 2.5 minutes\n",
      "Preds: 1200  - Total time: 94.68 seconds - ETA: 2.6 minutes\n",
      "Preds: 1300  - Total time: 114.98 seconds - ETA: 2.9 minutes\n",
      "Preds: 1400  - Total time: 129.69 seconds - ETA: 3.1 minutes\n",
      "Preds: 1500  - Total time: 142.77 seconds - ETA: 3.2 minutes\n",
      "Preds: 1600  - Total time: 150.28 seconds - ETA: 3.1 minutes\n",
      "Preds: 1700  - Total time: 155.36 seconds - ETA: 3.0 minutes\n",
      "Preds: 1800  - Total time: 161.7 seconds - ETA: 3.0 minutes\n",
      "Preds: 1900  - Total time: 169.96 seconds - ETA: 3.0 minutes\n",
      "Preds: 2000  - Total time: 178.05 seconds - ETA: 3.0 minutes\n"
     ]
    }
   ],
   "source": [
    "results = zeroberto.runZeroberto(model,train_data['text'],zeroshot_config)  ##X## COMENTAR AQUI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1: {'accuracy': 0.5}\n",
      "top 2: {'accuracy': 0.75}\n",
      "top 3: {'accuracy': 0.8333333333333334}\n",
      "top 4: {'accuracy': 0.75}\n",
      "top 5: {'accuracy': 0.75}\n",
      "top 6: {'accuracy': 0.7083333333333334}\n",
      "top 7: {'accuracy': 0.75}\n",
      "top 8: {'accuracy': 0.78125}\n",
      "top 9: {'accuracy': 0.7777777777777778}\n",
      "top 10: {'accuracy': 0.8}\n",
      "top 11: {'accuracy': 0.7954545454545454}\n",
      "top 12: {'accuracy': 0.8125}\n",
      "top 13: {'accuracy': 0.8269230769230769}\n",
      "top 14: {'accuracy': 0.8392857142857143}\n",
      "top 15: {'accuracy': 0.8333333333333334}\n",
      "top 16: {'accuracy': 0.828125}\n",
      "top 2000: {'accuracy': 0.5915}\n",
      "predictions_and_probabilities_test_2023_02_17__07_30_06.csv\n",
      "zeroshot_config_test_2023_02_17__07_30_06.csv\n"
     ]
    }
   ],
   "source": [
    "df_results = model.evaluateLabeling(results)\n",
    "all_metrics = evaluation_metrics.get_metrics(df_results['prediction_code'].to_list(),df_results['class_code'].to_list())\n",
    "zeroshot_config['trainings_done'] += 1\n",
    "save_time = evaluation_metrics.saveZeroshotResults(zeroshot_config,df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_config['exec_time'] = save_time\n",
    "\n",
    "zeroshot_previous_data = datasets_handler.getZeroshotPreviousData(which_dataset,class_col,top_n=top_n,exec_time=zeroshot_config['exec_time'])\n",
    "raw_data_final, zeroshot_config['new_class_col'] = datasets_handler.mergeLabelingToDataset(raw_data,zeroshot_previous_data,class_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = datasets_handler.splitDataset(raw_data_final,zeroshot_config)\n",
    "train_dataset,test_dataset = datasets_handler.buildDatasetDict(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 128.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df02d164277e4ce3b52e0f358b2d1f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train_dataset = train_dataset\n",
    "trainer.test_dataset = test_dataset\n",
    "\n",
    "trainer.unfreeze(keep_body_frozen=False)\n",
    "\n",
    "trainer.train(\n",
    "    num_epochs=zeroshot_config[\"num_epochs\"], # The number of epochs to train the head or the whole model (body and head)\n",
    "    batch_size=zeroshot_config[\"batch_size\"],\n",
    "    body_learning_rate=1e-5, # The body's learning rate\n",
    "    learning_rate=1e-2, # The head's learning rate\n",
    "    l2_weight=0.1, # Weight decay on **both** the body and head. If `None`, will use 0.01.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions on 2000 sentences.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "y_pred = zeroberto.getPredictions(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weighted': [{'accuracy': 0.6045}, {'precision': 0.6950742046267486}, {'recall': 0.6045}, {'f1': 0.5852444221212971}], 'macro': [{'accuracy': 0.6045}, {'precision': 0.6950742046267486}, {'recall': 0.6045}, {'f1': 0.5852444221212971}]}\n"
     ]
    }
   ],
   "source": [
    "all_metrics = evaluation_metrics.get_metrics(y_pred ,test_dataset[\"class_code\"])\n",
    "print(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_zeroberto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b98a7e24f8a69e8a460c693288d2fe0565d17bd4bdd6eb6203258b225132cc92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
